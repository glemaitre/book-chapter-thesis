\subsection{Segmentation}\label{subsec:chp3:img-reg:seg}
The segmentation task consists in delineating the prostate boundaries in the
\ac{mri} and is of particular importance for focusing the posterior processing
on the organ of interest~\cite{Ghose2012}.
In this section, only the segmentation methods used in \ac{cad} for \ac{cap}
are presented.
An exhaustive review of prostate segmentation methods in \ac{mri} is available
in~\cite{Ghose2012}.

\setenumerate{listparindent=\parindent,itemsep=10px}
\setlist{noitemsep}
\begin{enumerate}[leftmargin=*]

\item[] \textbf{Manual segmentation}
To highlight the importance of prostate segmentation task in \ac{cad} systems,
it is interesting to note the large number of studies which manually segment
the prostate
organs~\cite{Artan2009,Artan2010,Matulewicz2013,Niaf2011,Niaf2012,Ozer2009,Ozer2010,Puech2009,Vos2008,Vos2008a,trigui2016classification,trigui2017automatic,lehaire2014computer}.
In all the cases, the boundaries of the prostate gland are manually defined in
order to limit further processing to only this area.
This approach ensures the right delineation of the organ, although is
subjective and prone to the rater variability; nevertheless this procedure is
highly time consuming and should be performed by a radiologist.

\item[] \textbf{Region-based segmentation}
\citeauthor{Litjens2012} used a multi-atlas-based segmentation using
multi-modal images --- i.e., \ac{t2w}-\ac{mri} and \ac{adc} map --- to segment
the prostate with an additional pattern recognition method to differentiate
\ac{cg} and \ac{pz}~\cite{Litjens2012}, as proposed in~\cite{Litjens2012a}.
This method consists in three different steps: (i) the registration between
each atlas and the multi-modal images, (ii) the atlas selection, and finally
(iii) the classification of the prostate voxels into either \ac{cg} or \ac{pz}
classes.
Each atlas and the \ac{mri} images are registered through two successive
registrations: a rigid registration to roughly align the atlases and the
\ac{mri} images followed by an elastic registration using a B-spline
transformation.
The cost function driving the registration is defined as the weighted sum of
the \ac{mi} of both \ac{t2w}-\ac{mri} and \ac{adc} map.
The final atlas is selected using either a majority voting or the \ac{staple}
approach~\cite{Warfield2004}.
Subsequently, each voxel within the prostate is classified either as \ac{cg} or
\ac{pz} using a \ac{lda} classifier.
Three types of features are considered to characterize the voxels: (i) anatomy,
(ii) intensity, and (iii) texture.
The relative position and the relative distance from the voxel to the border of
the prostate encode the anatomical information.
The intensity features consist in the intensity of the voxel in the \ac{adc}
coefficient and the T$_2$ map.
The texture features are composed of 5 different features: homogeneity,
correlation~\cite{Amadasun1989}, entropy, texture strength~\cite{Li2005a}, and
\ac{lbp}~\cite{Ojala1996}.
Finally, the final segmentation is obtained by removing artifacts and smoothing
the contour between the zones using the \ac{tps}~\cite{Bookstein1989}.

\citeauthor{Litjens2014} used an almost identical algorithm
in~\cite{Litjens2014}, initially proposed for the PROMISE12
challenge~\cite{Litjens2014a}.
Their segmentation method is also based on multi-atlas multi-modal images, but
the SIMPLE method~\cite{langerak2010label} is used instead, to combine labels
after the registration of the different atlas to obtain the final
segmentation.

Finally, \citeauthor{rampun2016computerb} recurrently used a method to segment
the
\ac{pz}~\cite{rampun2015classifying,rampun2015computer,rampun2016computer,rampun2016computerb,rampun2016quantitative},
which is proposed in~\cite{rampun2014detection}.
The \ac{pz} is modelled using a quadratic function driven by the centre of the
prostate, the left-most, and the right-most coordinates of the prostate
boundaries.

\item[] \textbf{Model-based segmentation:}
\citeauthor{Viswanath2009}~\cite{Viswanath2008a,Viswanath2009} used the
\acs{mantra} method~\cite{Toth2008}.
\Acf{mantra} \cite{Toth2008} is closely related to the \ac{asm}
from~\cite{Cootes1995}.
This algorithm consists of two stages: (i) a training stage where a shape and
an appearance model are generated and (ii) the actual segmentation based on the
learned model.
For the training stage, a set of landmarks is defined and the shape model is
generated as in the original \ac{asm} method~\cite{Cootes1995}.
Then, to model the appearance, a set of $K$ texture images
$\{I_1,I_2,\cdots,I_k\}$ based on first and second order statistical texture
features is computed.
For a given landmark $l$ with its given neighbourhood $\mathcal{N}(l)$, its
feature matrix extracted is expressed as:

\begin{equation}
  f_l = \{ I_1(\mathcal{N}(l)), I_2(\mathcal{N}(l)), \cdots, I_k(\mathcal{N}(l)) \} \ ,
  \label{eq:mantra1}
\end{equation}

\noindent where $I_k(\mathcal{N}(l))$ represents a feature vector obtained by
sampling the $k^{\text{th}}$ texture map using the neighbourhood
$\mathcal{N}(l)$.
Therefore, multiple landmarks are generated followed by a decomposition using
\ac{pca}~\cite{Pearson1901} to learn the appearance variations as in \ac{asm}.

For the segmentation stage, the mean shape learned previously is initialized in
the test image.
The same associated texture images as in the training stage are computed.
For each landmark $l$, a neighbourhood of patches are used to sample the
texture images and a reconstruction is obtained using the appearance model
previously trained.
The new landmark location will be defined as the position where the \ac{mi} is
maximal between the reconstructed and original values.
This scheme is performed in a multi-resolution manner as in \cite{Cootes1995}.

Subsequently, \citeauthor{Viswanath2012} in~\cite{Viswanath2012}, used the
\ac{weritas} method also proposed in~\citeauthor{Toth2009}.
Similarly to \ac{mantra}, \ac{weritas} is also based on the \ac{asm}
formulation~\cite{Toth2009}.
It differs in the last stage of the algorithm in which the Mahalanobis distance
is used instead of the \ac{mi} metric, to adapt the positions of new
landmarks.
In the training stage, the Mahalanobis distance is computed between landmarks
and neighbour patches for each of the features.
Subsequently, a new metric is proposed as a linear weighted combination of
those Mahalanobis distances which maximizes the correlation with the Euclidean
distance between the patches and the true landmarks.
In the segmentation step, this metric is then computed between the initialized
landmarks and neighbouring patches in order to update landmark positions, in a
similar fashion to other \ac{acm} models.

\citeauthor{Litjens2011} as well as \citeauthor{Vos2012} used an approach
proposed in~\cite{Huisman2010} in which the bladder, the prostate, and the
rectum are segmented~\cite{Litjens2011,Vos2012}.
The segmentation task is performed as an optimization problem taking 3
parameters into account linked to organ characteristics such as: (i) the shape
(i.e., an ellipse), (ii) the location, and (iii) the respective angles between
them.
Furthermore, \citeauthor{Litjens2011} used only the \ac{adc} map to encode the
appearance~\cite{Litjens2011} whereas \citeauthor{Vos2012} used both \ac{adc}
and T$_2$ maps~\cite{Vos2012}.
The cost function, defined as the sum of the deviations, is minimized using a
quasi-Newton optimizer.
This rough segmentation is then used inside a Bayesian framework to refine the
segmentation.

\citeauthor{giannini2015fully} segmented the prostate with a multi-Otsu
thresholding~\cite{otsu1975threshold} in \ac{adc}
images~\cite{giannini2015fully}.
Further morphological operations are applied to improve the segmentation.

Only the work of \citeauthor{Tiwari2009} used the \ac{mrsi} modality to segment
the prostate organ~\cite{Tiwari2009}.
The prostate is segmented based on an unsupervised hierarchical spectral
clustering.
First, each \ac{mrsi} spectrum is projected into a lower-dimensional space
using graph embedding~\cite{Shi2000}.
To proceed, a similarity matrix $W$ is computed using a Gaussian similarity
measure from Euclidean distance~\cite{Belkin2001} such that:

\begin{equation}
  W(\mathbf{x},\mathbf{y}) =
  \begin{cases}
    \exp \left( \frac{\| s(\mathbf{x}) - s(\mathbf{y}) \|_2^2}{\sigma^2}
    \right) \ , & \text{if } \| \mathbf{x} - \mathbf{y} \|_2 < \epsilon \ , \\
    0 \ , & \text{if } \| \mathbf{x} - \mathbf{y} \|_2 > \epsilon \ .
  \end{cases}
  \label{eq:ge1}
\end{equation}

\noindent where $s(\mathbf{x})$ and $s(\mathbf{y})$ are the \ac{mrsi} spectra
for the voxels $\mathbf{x}$ and $\mathbf{y}$, respectively, $\sigma$ is the
standard deviation of the Gaussian similarity measure, and $\epsilon$ is the
parameter to defined an $\epsilon$-neighbourhood.

The projection can be performed as a generalized eigenvector problem such that:
\begin{eqnarray}
  Lu & = & \lambda D u \ , \nonumber \\
  D(\mathbf{x},\mathbf{x}) & = & \sum_{\mathbf{y}} W(\mathbf{x},\mathbf{y}) \
                                 , \label{eq:ge2} \\
  L & = & D-W \ , \nonumber
\end{eqnarray}

\noindent where $D$ is the diagonal weight matrix, $L$ is the Laplacian matrix,
$\lambda$ and $u$ represent the eigenvalues and eigenvectors.
Once the \ac{mrsi} spectra are projected into the lower-dimensional space, a
replicate k-means clustering method is used to define 2 clusters.
Subsequently, the data corresponding to the largest cluster is assumed to
belong to the non-prostate voxels and thus these voxels are eliminated from the
processing.
The full procedure is repeated until the total number of voxels left is
inferior to a given threshold experimentally set.

\end{enumerate}

The segmentation algorithms used in \ac{cad} system for the detection of
\ac{cap} are summarized in \ac{tab}~\ref{tab:summary-seg}.

\begin{table}
  \caption{Overview of the segmentation methods used in \ac{cad} systems.}
  \centering
  \begin{tabular}{l r}
    \toprule
    \textbf{Segmentation methods} & \textbf{References} \\
    \midrule
    \textbf{\ac{mri}-based segmentation:} & \\ \\ [-1.5ex]
    \quad Manual segmentation &
                                \cite{Artan2009,Artan2010,Matulewicz2013,Niaf2011,Niaf2012,Ozer2009,Ozer2010,Puech2009,Vos2008,Vos2008a,Vos2010,Vos2012,trigui2016classification,trigui2017automatic,lehaire2014computer,Lemaitre2016thesis}
    \\
    \quad Region-based segmentation &
                                      \cite{Litjens2012,Litjens2014,rampun2015classifying,rampun2015computer,rampun2016computer,rampun2016computerb,rampun2016quantitative}
    \\
    \quad Model-based segmentation &
                                     \cite{Litjens2011,Viswanath2008a,Viswanath2009,Viswanath2011,Vos2012,giannini2015fully}
    \\ \\ [-1.5ex]
    \textbf{\ac{mrsi}-based segmentation:} & \\ \\ [-1.5ex]
    \quad Clustering & \cite{Tiwari2009} \\
    \bottomrule
  \end{tabular}
  \label{tab:summary-seg}
\end{table}
